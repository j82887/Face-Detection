{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import dlib\n",
    "\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "model = keras.models.load_model('Model/model.h5')\n",
    "detector = dlib.get_frontal_face_detector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_faces(frame):\n",
    "    \n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    face = detector(frame)\n",
    "    faces = []\n",
    "    \n",
    "    for i in range(len(face)):\n",
    "        x = face[i].left()\n",
    "        y = face[i].top()\n",
    "        w = face[i].right()-face[i].left()\n",
    "        h = face[i].bottom()-face[i].top()\n",
    "        \n",
    "        if x<0:\n",
    "            x = 0\n",
    "        if y<0:\n",
    "            y = 0\n",
    "            \n",
    "        faces.append((x, y, w, h))\n",
    "        \n",
    "    return gray, faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def face_check(img, model):\n",
    "    \n",
    "    frame = img\n",
    "    \n",
    "    gray, faces = detect_faces(frame)\n",
    "    \n",
    "    data = {\"faces\" : []}\n",
    "    \n",
    "    for i, (x, y, w, h) in enumerate(faces):\n",
    "        \n",
    "        roi_gray = gray[y:y + h, x:x + w]\n",
    "        \n",
    "        cropped_img = np.expand_dims(np.expand_dims(cv2.resize(roi_gray, (48, 48)), -1), 0)\n",
    "        \n",
    "        cv2.normalize(cropped_img, cropped_img, alpha=0, beta=1, norm_type=cv2.NORM_L2, dtype=cv2.CV_32F)\n",
    "        \n",
    "        prediction = model.predict(cropped_img)[0]\n",
    "        \n",
    "        pred_array = prediction.tolist()\n",
    "        \n",
    "        predictions = {\n",
    "            \"angry\": float(prediction[0]),\n",
    "            \"disgusted\": float(prediction[1]),\n",
    "            \"fearful\": float(prediction[2]),\n",
    "            \"happy\": float(prediction[3]),\n",
    "            \"sad\": float(prediction[4]),\n",
    "            \"surprised\": float(prediction[5]),\n",
    "            \"neutral\": float(prediction[6])\n",
    "        }\n",
    "        \n",
    "        data[\"faces\"].append({\"id\" : i,\"xywh\": (x, y, w, h),\"predictions\": predictions})\n",
    "        \n",
    "        # 提取最大機率與預測名稱\n",
    "        probability = predictions[max(predictions, key=predictions.get)]\n",
    "        prediction_name = max(predictions, key=predictions.get)\n",
    "        g = b = int((1-probability)*255)\n",
    "        \n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (g, b, 255), 4)\n",
    "        \n",
    "        # 機率沒大於0.6則不顯示\n",
    "        #if predictions[max(predictions, key=predictions.get)]<0.6:\n",
    "        #    continue\n",
    "        \n",
    "        # 繪製文字\n",
    "        #cv2.putText(frame,prediction_name,(x, y-28),font, 0.5,(0,0,255),2)\n",
    "        #cv2.putText(frame,str(round(probability,3)),(x, y-10),font, 0.5,(0,0,255),2)\n",
    "        \n",
    "        frame = face_post(frame, (x, y), (x+w, y), (x+w, y+h), (x, y+h), w, max(predictions, key=predictions.get), faces)\n",
    "    \n",
    "    # 繪製Bar\n",
    "    frame = bar_post(frame,int(frame.shape[0]/10),int(frame.shape[0]/10))\n",
    "    \n",
    "    return data, frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bar_post(frame, x, y):\n",
    "    \n",
    "    # 以shape來獲取畫面的高與寬，並以高的三分之一作為bar的高，三十分之一則作為bar的寬\n",
    "    h, w, channel = frame.shape\n",
    "    bar_h = int(h/3)\n",
    "    bar_w = int(h/(3*10))\n",
    "    \n",
    "    # 產生陣列r為255像素，其中高為256，寬為10; 產生陣列g, b為0由高漸增至255像素，其中高為256，寬為10\n",
    "    r = np.outer(np.array([255]*256),np.ones(10))\n",
    "    g = b = np.outer(np.arange(0,256,1),np.ones(10))\n",
    "    \n",
    "    # RGB陣列結合且轉為浮點數，並改為bar的寬與高\n",
    "    img = cv2.merge([b, g, r]).astype(np.float32)\n",
    "    img = cv2.resize(img,(bar_w, bar_h))\n",
    "    \n",
    "    # 將bar放入指定位置\n",
    "    frame[y: y+bar_h, x: x+bar_w] = img\n",
    "    \n",
    "    cv2.putText(frame,\"1\",(x,int(y-0.5*bar_w)), font, h/700, (0,0,255), int(h/175))\n",
    "    cv2.putText(frame,\"0\",(x,int(y+bar_h+1.5*bar_w)),font, h/700, (0,0,255), int(h/175))   \n",
    "    \n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bb_intersection_over_union(boxA, boxB):\n",
    "    boxA = [int(x) for x in boxA]\n",
    "    boxB = [int(x) for x in boxB]\n",
    "\n",
    "    xA = max(boxA[0], boxB[0])\n",
    "    yA = max(boxA[1], boxB[1])\n",
    "    xB = min(boxA[2], boxB[2])\n",
    "    yB = min(boxA[3], boxB[3])\n",
    "\n",
    "    interArea = max(0, xB - xA + 1) * max(0, yB - yA + 1)\n",
    "\n",
    "    boxAArea = (boxA[2] - boxA[0] + 1) * (boxA[3] - boxA[1] + 1)\n",
    "    boxBArea = (boxB[2] - boxB[0] + 1) * (boxB[3] - boxB[1] + 1)\n",
    "    \n",
    "    iou = interArea / float(boxAArea + boxBArea - interArea)\n",
    "\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def face_post(frame, top_left, top_right, bottom_right, bottom_left, width, prediction, faces):\n",
    "    \n",
    "    if prediction ==\"angry\":\n",
    "        img = cv2.imread(\"Image_fer/00_Angry_Second.png\")\n",
    "    if prediction ==\"disgusted\":\n",
    "        img = cv2.imread(\"Image_fer/01_Disgust_Second.png\")\n",
    "    if prediction ==\"fearful\":\n",
    "        img = cv2.imread(\"Image_fer/02_Fear_Second.png\")\n",
    "    if prediction ==\"happy\":\n",
    "        img = cv2.imread(\"Image_fer/03_Happy_Second.png\")\n",
    "    if prediction ==\"sad\":\n",
    "        img = cv2.imread(\"Image_fer/04_Sad_Second.png\")\n",
    "    if prediction ==\"surprised\":\n",
    "        img = cv2.imread(\"Image_fer/05_Surprise_Second.png\")\n",
    "    if prediction ==\"neutral\":\n",
    "        img = cv2.imread(\"Image_fer/06_Neutral_Second.png\")\n",
    "    \n",
    "    img_wh = int(width/2)\n",
    "    img = cv2.resize(img, (img_wh,img_wh))\n",
    "    \n",
    "    IoU_rbr, IoU_rtr, IoU_lbl, IoU_ltl, IoU_rbb, IoU_lbb, IoU_rtt, IoU_ltt = [], [], [], [], [], [], [], []\n",
    "    img_loc = []\n",
    "    \n",
    "    for (x, y, w, h) in faces:\n",
    "        \n",
    "        # 計算左上角與右下角\n",
    "        \n",
    "        # 人臉右下右半邊 （由於貼圖與人臉同X軸計算IOU會非零，故貼圖平移右一像素）\n",
    "        img_top_left = (int(bottom_right[0]),int(bottom_right[1]-img_wh))\n",
    "        img_bottom_right = (int(bottom_right[0]+img_wh),int(bottom_right[1]))\n",
    "        img_loc.append((img_top_left,img_bottom_right))\n",
    "        IoU_rbr.append(bb_intersection_over_union([img_top_left[0]+1,img_top_left[1],img_bottom_right[0]+1,img_bottom_right[1]],[x, y, x+w, y+h]))\n",
    "        \n",
    "        # 人臉右上右半邊 （由於貼圖與人臉同X軸計算IOU會非零，故貼圖平移右一像素）# 新增\n",
    "        img_top_left = (int(top_right[0]),int(top_right[1]))\n",
    "        img_bottom_right = (int(top_right[0]+img_wh),int(top_right[1]+img_wh))\n",
    "        img_loc.append((img_top_left,img_bottom_right))\n",
    "        IoU_rtr.append(bb_intersection_over_union([img_top_left[0]+1,img_top_left[1],img_bottom_right[0]+1,img_bottom_right[1]],[x, y, x+w, y+h]))\n",
    "        \n",
    "        # 人臉左下左半邊 （由於貼圖與人臉同X軸計算IOU會非零，故貼圖平移左一像素）# 新增\n",
    "        img_top_left = (int(bottom_left[0]-img_wh),int(bottom_left[1]-img_wh))\n",
    "        img_bottom_right = (int(bottom_left[0]),int(bottom_left[1]))\n",
    "        img_loc.append((img_top_left,img_bottom_right))\n",
    "        IoU_lbl.append(bb_intersection_over_union([img_top_left[0]-1,img_top_left[1],img_bottom_right[0]-1,img_bottom_right[1]],[x, y, x+w, y+h]))\n",
    "        \n",
    "        # 人臉左上左半邊 （由於貼圖與人臉同X軸計算IOU會非零，故貼圖平移左一像素）\n",
    "        img_top_left = (int(top_left[0]-img_wh),int(top_left[1]))\n",
    "        img_bottom_right = (int(top_left[0]),int(top_left[1]+img_wh))\n",
    "        img_loc.append((img_top_left,img_bottom_right))\n",
    "        IoU_ltl.append(bb_intersection_over_union([img_top_left[0]-1,img_top_left[1],img_bottom_right[0]-1,img_bottom_right[1]],[x, y, x+w, y+h]))\n",
    "        \n",
    "        # 人臉右下下半邊 （由於貼圖與人臉同Y軸計算IOU會非零，故貼圖平移下一像素）# 新增\n",
    "        img_top_left = (int(bottom_right[0]-img_wh),int(bottom_right[1]))\n",
    "        img_bottom_right = (int(bottom_right[0]),int(bottom_right[1]+img_wh))\n",
    "        img_loc.append((img_top_left,img_bottom_right))\n",
    "        IoU_rbb.append(bb_intersection_over_union([img_top_left[0],img_top_left[1]+1,img_bottom_right[0],img_bottom_right[1]+1],[x, y, x+w, y+h]))\n",
    "        \n",
    "        # 人臉左下下半邊 （由於貼圖與人臉同Y軸計算IOU會非零，故貼圖平移下一像素）\n",
    "        img_top_left = (int(bottom_left[0]),int(bottom_left[1]))\n",
    "        img_bottom_right = (int(bottom_left[0]+img_wh),int(bottom_left[1]+img_wh))\n",
    "        img_loc.append((img_top_left,img_bottom_right))\n",
    "        IoU_lbb.append(bb_intersection_over_union([img_top_left[0],img_top_left[1]+1,img_bottom_right[0],img_bottom_right[1]+1],[x, y, x+w, y+h]))\n",
    "        \n",
    "        # 人臉右上上半邊 （由於貼圖與人臉同Y軸計算IOU會非零，故貼圖平移上一像素）\n",
    "        img_top_left = (int(top_right[0]-img_wh),int(top_right[1]-img_wh))\n",
    "        img_bottom_right = (int(top_right[0]),int(top_right[1]))\n",
    "        img_loc.append((img_top_left,img_bottom_right))\n",
    "        IoU_rtt.append(bb_intersection_over_union([img_top_left[0],img_top_left[1]-1,img_bottom_right[0],img_bottom_right[1]-1],[x, y, x+w, y+h]))\n",
    "        \n",
    "        # 人臉左上上半邊 （由於貼圖與人臉同Y軸計算IOU會非零，故貼圖平移上一像素）# 新增\n",
    "        img_top_left = (int(top_left[0]),int(top_left[1]-img_wh))\n",
    "        img_bottom_right = (int(top_left[0]+img_wh),int(top_left[1]))\n",
    "        img_loc.append((img_top_left,img_bottom_right))\n",
    "        IoU_ltt.append(bb_intersection_over_union([img_top_left[0],img_top_left[1]-1,img_bottom_right[0],img_bottom_right[1]-1],[x, y, x+w, y+h]))\n",
    "        \n",
    "        # 將左上與右下變數改為零，之後在IOU皆為零時會用到\n",
    "        img_top_left = 0\n",
    "        img_bottom_right = 0\n",
    "        \n",
    "    # 判斷貼圖與其他人臉的IOU是否為零，並針對四個角落，以及貼圖是否超過邊界之判斷\n",
    "    Iou_total = [IoU_rbr, IoU_rtr, IoU_lbl, IoU_ltl, IoU_rbb, IoU_lbb, IoU_rtt, IoU_ltt]\n",
    "    for i in range(len(Iou_total)):\n",
    "        if np.all(np.array(Iou_total[i]) == 0):\n",
    "            if img_loc[i][0][0]>0 and img_loc[i][0][1]>0 and img_loc[i][1][0]<frame.shape[1] and img_loc[i][1][1]<frame.shape[0]:\n",
    "                img_top_left, img_bottom_right = img_loc[i]\n",
    "\n",
    "    # 將左上與右下變數為非零時才貼圖，即上面非四個條件式都為Flase時才貼圖\n",
    "    if img_top_left != 0 and img_bottom_right != 0:\n",
    "        \n",
    "        # 轉為灰階\n",
    "        img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # 二值化\n",
    "        _, mask = cv2.threshold(img_gray, 25, 255, cv2.THRESH_BINARY_INV)\n",
    "    \n",
    "        area = frame[img_top_left[1]: img_top_left[1]+img_wh, img_top_left[0]: img_top_left[0]+img_wh]\n",
    "        area_no = cv2.bitwise_and(area,area,mask=mask)\n",
    "        final = cv2.add(area_no, img)\n",
    "        frame[img_top_left[1]: img_top_left[1]+img_wh, img_top_left[0]: img_top_left[0]+img_wh] = final\n",
    "\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "VIDEO_IN = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    hasFrame, img = VIDEO_IN.read()\n",
    "    img = cv2.resize(img, None, fx=0.5, fy=0.5)\n",
    "    data, img = face_check(img, model)\n",
    "    cv2.imshow(\"Frame\", img)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "        \n",
    "VIDEO_IN.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk \n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from tkinter import ttk\n",
    "from tkinter import messagebox \n",
    "from tkinter.font import Font \n",
    "from PIL import ImageTk, Image \n",
    "from tkinter import messagebox \n",
    "from tkinter.filedialog import askopenfilename\n",
    "from tensorflow.keras.models import load_model\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#建立選擇欄\n",
    "def NewFile():\n",
    "    print(\"New File!\")\n",
    "def About():\n",
    "    messagebox.showinfo(title='About', message=\"本研究東華大學測試使用!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_text():\n",
    "    for i in range(len(entry_L)):\n",
    "        entry_L[i].delete(0, 'end')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#建立視窗\n",
    "app = tk.Tk()\n",
    "\n",
    "#建立視窗標題\n",
    "app.title('Facial Expression Recognition')\n",
    "\n",
    "#建立視窗背景\n",
    "#app.configure(background = 'white')\n",
    "\n",
    "#建立視窗大小\n",
    "app.geometry('460x440')\n",
    "\n",
    "#=================================================================\n",
    "#建立菜單\n",
    "menu = tk.Menu(app)\n",
    "app.config(menu=menu)\n",
    "\n",
    "#建立菜單的file\n",
    "file_menu = tk.Menu(menu, tearoff = 0) #是否有虛線，無虛線則無法分離視窗\n",
    "menu.add_cascade(label=\"File\", menu=file_menu)\n",
    "\n",
    "#file建立新增\n",
    "file_menu.add_command(label=\"New\", command=NewFile)\n",
    "\n",
    "#file建立虛線\n",
    "file_menu.add_separator()\n",
    "\n",
    "#file建立離開\n",
    "file_menu.add_command(label=\"Exit\", command=app.destroy)\n",
    "\n",
    "#建立菜單的幫助\n",
    "help_menu = tk.Menu(menu, tearoff = 0)\n",
    "menu.add_cascade(label=\"Help\", menu=help_menu)\n",
    "help_menu.add_command(label=\"About\", command=About)\n",
    "\n",
    "#=================================================================\n",
    "#設立字體\n",
    "title_label_Font = Font(family=\"Times\", size=18, underline=1)\n",
    "subtitle_label_Font_1 = Font(family=\"Times\", size=14)\n",
    "\n",
    "#建立畫布與位置\n",
    "frame_title = tk.Frame(app)\n",
    "frame_title.grid(column=0, row=0, ipadx=5, pady=5)\n",
    "\n",
    "frame_input = tk.LabelFrame(app, text='Threshold, Image and Display')\n",
    "frame_input.grid(column=0, row=1, ipadx=0, padx=20, pady=5, sticky=tk.W+tk.N)\n",
    "\n",
    "frame_output = tk.Frame(app)\n",
    "frame_output.grid(column=0, row=2, ipadx=5, pady=5)\n",
    "\n",
    "# =================================================================\n",
    "# 建立標題與位置\n",
    "label_Title = tk.Label(frame_title,text=\"Facial Expression Recognition\", font=title_label_Font)\n",
    "label_Title.grid(column=0, row=0, ipadx=5, pady=5)\n",
    "\n",
    "label_Subtitle = tk.Label(frame_title,text=\"Please enter the threshold and image.\", font=subtitle_label_Font_1)\n",
    "label_Subtitle.grid(column=0, row=1, ipadx=5, pady=5)\n",
    "\n",
    "# =================================================================\n",
    "# 勾選Checkbutton變數    \n",
    "\n",
    "chk_Var = []\n",
    "for i in range(len(label_name_L)):\n",
    "    chkValue = tk.BooleanVar() \n",
    "    chkValue.set(False)\n",
    "    chk_Var.append(chkValue)\n",
    "\n",
    "# =================================================================\n",
    "# 模型名稱與輸入欄的放置位置(左與右)\n",
    "label_name_L = ['Angry', 'Disgusted', 'Fearful', 'Happy', 'Sad', 'Surprised', 'Neutral']\n",
    "\n",
    "#fun_command = [open_img_Angry, open_img_Disgusted, open_img_Fearful, open_img_Happy, open_img_Sad, open_img_Surprised, open_img_Neutral]\n",
    "\n",
    "entry_L, button_model = [], []\n",
    "\n",
    "for i in range(len(label_name_L)):\n",
    "    label = tk.Label(frame_input,text = label_name_L[i])\n",
    "    label.grid(column=0, row=2+i, ipadx=5, pady=5, sticky=tk.W+tk.N)\n",
    "    \n",
    "    entry_L.append(tk.Entry(frame_input, width=10))\n",
    "    entry_L[i].grid(column=1, row=2+i, padx=10, pady=5, sticky=tk.N)\n",
    "    \n",
    "    button_model.append(tk.Button(frame_input, text = 'Open Image',command = None)) # fun_command[i]\n",
    "    button_model[i].grid(column=2, row=2+i, padx=10, pady=5, sticky=tk.N)\n",
    "\n",
    "    chkExample = tk.Checkbutton(frame_input, text=None, var=chk_Var[i]) \n",
    "    chkExample.grid(column=3, row=2+i, padx=10, pady=5, sticky=tk.W)\n",
    "\n",
    "#=================================================================\n",
    "#放置變數\n",
    "imgpath_Var = []\n",
    "for i in range(len(label_name_L)):\n",
    "    var = tk.StringVar()\n",
    "    imgpath_Var.append(var)\n",
    "    \n",
    "#=================================================================\n",
    "#建立按鈕與位置\n",
    "resultButton = tk.Button(frame_output, text = 'Get Result',command = None)\n",
    "resultButton.grid(column=0, row=0, pady=10)\n",
    "\n",
    "clear_button = tk.Button(frame_output, text=\" Clear text\", command = clear_text)\n",
    "clear_button.grid(column=1, row=0, pady=10)\n",
    "\n",
    "#程式開始迴圈\n",
    "app.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
