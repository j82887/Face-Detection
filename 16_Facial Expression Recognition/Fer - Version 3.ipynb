{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "model = keras.models.load_model('Model/model.h5')\n",
    "\n",
    "# 定義標籤的字典與顏色\n",
    "expression_dict = {0: \"Angry\", 1: \"Disgust\", 2: \"Fear\", 3: \"Happy\", 4: \"Sad\", 5: \"Surprise\", 6: \"Neutral\"}\n",
    "colors = [(0,0,255),(0,0,0),(135,138,128),(18,153,255),(255,0,0),(240,32,160),(0,255,0)]\n",
    "# 0:紅色, 1:黑色, 2:灰色, 3:橘色, 4:藍色, 5:紫色, 6:綠色\n",
    "# 0:生氣, 1:厭惡, 2:恐懼, 3:開心, 4:難過, 5:驚訝, 6:中立\n",
    "\n",
    "# 匯入人臉辨識器\n",
    "import dlib\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "\n",
    "# 建立detect_faces方法\n",
    "def detect_faces(frame):\n",
    "    \n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # 使用Dlib獲取人臉\n",
    "    face = detector(frame)\n",
    "    \n",
    "    # 建立初始空的列表\n",
    "    faces = []\n",
    "    \n",
    "    # 將畫面中的人臉依序存放左上角座標與寬高\n",
    "    for i in range(len(face)):\n",
    "        x = face[i].left()\n",
    "        y = face[i].top()\n",
    "        w = face[i].right()-face[i].left()\n",
    "        h = face[i].bottom()-face[i].top()\n",
    "        if x<0:\n",
    "            x = 0\n",
    "        if y<0:\n",
    "            y = 0\n",
    "        faces.append((x, y, w, h))\n",
    "        \n",
    "    return gray, faces\n",
    "\n",
    "# 建立face_check方法\n",
    "def face_check(img, model):\n",
    "    \n",
    "    frame = img\n",
    "    \n",
    "    # 代入detect_faces方法\n",
    "    gray, faces = detect_faces(frame)\n",
    "    \n",
    "    # 建立只有key(faces)沒有元素得的空字典\n",
    "    data = {\"faces\" : []}\n",
    "    \n",
    "    # 將每次的人臉左上角座標與寬高代入迴圈\n",
    "    for i, (x, y, w, h) in enumerate(faces):\n",
    "        \n",
    "        # 透過座標與寬高得到灰階的人臉區域\n",
    "        roi_gray = gray[y:y + h, x:x + w]\n",
    "        \n",
    "        # 陣列改變大小，並且內外增加維度，使可以帶入模型的輸入形式\n",
    "        cropped_img = np.expand_dims(np.expand_dims(cv2.resize(roi_gray, (48, 48)), -1), 0)\n",
    "        \n",
    "        # 像素進行正規化\n",
    "        cv2.normalize(cropped_img, cropped_img, alpha=0, beta=1, norm_type=cv2.NORM_L2, dtype=cv2.CV_32F)\n",
    "        \n",
    "        # 將輸入代入模型進行預測\n",
    "        prediction = model.predict(cropped_img)[0]\n",
    "        \n",
    "        # 轉為列表\n",
    "        pred_array = prediction.tolist()\n",
    "        \n",
    "        # 建立字典，將單張人臉的預測結果以浮點數方式儲存\n",
    "        predictions = {\n",
    "            \"angry\": float(prediction[0]),\n",
    "            \"disgusted\": float(prediction[1]),\n",
    "            \"fearful\": float(prediction[2]),\n",
    "            \"happy\": float(prediction[3]),\n",
    "            \"sad\": float(prediction[4]),\n",
    "            \"surprised\": float(prediction[5]),\n",
    "            \"neutral\": float(prediction[6])\n",
    "        }\n",
    "        \n",
    "        # 將（數張）人臉儲存至data的字典之key的faces中\n",
    "        data[\"faces\"].append({\"id\" : i,\"xywh\": (x, y, w, h),\"predictions\": predictions})\n",
    "        \n",
    "        # 繪製矩形\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 0, 255), 4)\n",
    "        \n",
    "        # 機率沒大於0.6則不顯示\n",
    "        #if predictions[max(predictions, key=predictions.get)]<0.6:\n",
    "        #    continue\n",
    "        \n",
    "        # 繪製文字\n",
    "        cv2.putText(frame,max(predictions, key=predictions.get),(x, y-28),cv2.FONT_HERSHEY_SIMPLEX,0.5,colors[pred_array.index(max(pred_array))],2)\n",
    "        cv2.putText(frame,str(round(predictions[max(predictions, key=predictions.get)],3)),(x, y-10),cv2.FONT_HERSHEY_SIMPLEX,0.5,colors[pred_array.index(max(pred_array))],2)\n",
    "        \n",
    "        # 繪製圖像\n",
    "        frame = face_post(frame, (x, y), (x+w, y), (x+w, y+h), (x, y+h), w, max(predictions, key=predictions.get), faces)\n",
    "        \n",
    "    return data, frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 10, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#r = np.outer(np.array([255]*256),np.ones(10)).astype(int)\n",
    "#g = b = np.outer(np.arange(0,256,1),np.ones(10)).astype(int)\n",
    "\n",
    "r = np.outer(np.array([1]*100),np.ones(10))\n",
    "g = b = np.outer(np.arange(0,1,0.01),np.ones(10))\n",
    "img = cv2.merge([r, g, b])\n",
    "\n",
    "print(img.shape)\n",
    "plt.imshow(img)                   \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bar_post(frame):\n",
    "    r = np.outer(np.array([255]*256),np.ones(10))\n",
    "    g = b = np.outer(np.arange(0,256,1),np.ones(10))\n",
    "    img = cv2.merge([r, g, b])\n",
    "    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    _, mask = cv2.threshold(img_gray, 25, 255, cv2.THRESH_BINARY_INV)\n",
    "    \n",
    "    area = frame[15: 15+256, 15: 15+10]\n",
    "    area_no = cv2.bitwise_and(area,area,mask=mask)\n",
    "    final = cv2.add(area_no, img)\n",
    "    frame[15: 15+100, 15: 15+10] = final\n",
    "    \n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.0.0) /Users/travis/build/skvark/opencv-python/opencv/modules/core/src/arithm.cpp:687: error: (-5:Bad argument) When the input arrays in add/subtract/multiply/divide functions have different types, the output array type must be explicitly specified in function 'arithm_op'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-78-274f983ab832>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Image_test/Face_test6.jpg\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbar_post\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-77-15a54f7d1a0e>\u001b[0m in \u001b[0;36mbar_post\u001b[0;34m(frame)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0marea\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0marea_no\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbitwise_and\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marea\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0marea\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mfinal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marea_no\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mframe\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.0.0) /Users/travis/build/skvark/opencv-python/opencv/modules/core/src/arithm.cpp:687: error: (-5:Bad argument) When the input arrays in add/subtract/multiply/divide functions have different types, the output array type must be explicitly specified in function 'arithm_op'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = cv2.imread(\"Image_test/Face_test6.jpg\")\n",
    "img = cv2.resize(img, None, fx=1.5, fy=1.5)\n",
    "img = bar_post(img)\n",
    "\n",
    "frame = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "plt.figure(figsize=(25,20))\n",
    "plt.imshow(frame)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bb_intersection_over_union(boxA, boxB):\n",
    "    boxA = [int(x) for x in boxA]\n",
    "    boxB = [int(x) for x in boxB]\n",
    "\n",
    "    xA = max(boxA[0], boxB[0])\n",
    "    yA = max(boxA[1], boxB[1])\n",
    "    xB = min(boxA[2], boxB[2])\n",
    "    yB = min(boxA[3], boxB[3])\n",
    "\n",
    "    interArea = max(0, xB - xA + 1) * max(0, yB - yA + 1)\n",
    "\n",
    "    boxAArea = (boxA[2] - boxA[0] + 1) * (boxA[3] - boxA[1] + 1)\n",
    "    boxBArea = (boxB[2] - boxB[0] + 1) * (boxB[3] - boxB[1] + 1)\n",
    "    \n",
    "    iou = interArea / float(boxAArea + boxBArea - interArea)\n",
    "\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def face_post(frame, top_left, top_right, bottom_right, bottom_left, width, prediction, faces):\n",
    "    \n",
    "    if prediction ==\"angry\":\n",
    "        img = cv2.imread(\"Image_fer/00_Angry_Second.png\")\n",
    "    if prediction ==\"disgusted\":\n",
    "        img = cv2.imread(\"Image_fer/01_Disgust_Second.png\")\n",
    "    if prediction ==\"fearful\":\n",
    "        img = cv2.imread(\"Image_fer/02_Fear_Second.png\")\n",
    "    if prediction ==\"happy\":\n",
    "        img = cv2.imread(\"Image_fer/03_Happy_Second.png\")\n",
    "    if prediction ==\"sad\":\n",
    "        img = cv2.imread(\"Image_fer/04_Sad_Second.png\")\n",
    "    if prediction ==\"surprised\":\n",
    "        img = cv2.imread(\"Image_fer/05_Surprise_Second.png\")\n",
    "    if prediction ==\"neutral\":\n",
    "        img = cv2.imread(\"Image_fer/06_Neutral_Second.png\")\n",
    "    \n",
    "    img_wh = int(width/2)\n",
    "    img = cv2.resize(img, (img_wh,img_wh))\n",
    "    \n",
    "    IoU_top_left, IoU_bottom_right, IoU_bottom_left, IoU_top_right = [], [], [], []\n",
    "    img_loc = []\n",
    "    \n",
    "    for (x, y, w, h) in faces:\n",
    "        \n",
    "        # 計算左上角與右下角\n",
    "        # 人臉左上半邊\n",
    "        # 由於貼圖與人臉同X軸計算IOU會非零，故貼圖平移左一像素\n",
    "        img_top_left = (int(top_left[0]-img_wh),int(top_left[1]))\n",
    "        img_bottom_right = (int(top_left[0]),int(top_left[1]+img_wh))\n",
    "        img_loc.append((img_top_left,img_bottom_right))\n",
    "        IoU_top_left.append(bb_intersection_over_union([img_top_left[0]-1,img_top_left[1],img_bottom_right[0]-1,img_bottom_right[1]],[x, y, x+w, y+h]))\n",
    "        \n",
    "        # 人臉右下半邊\n",
    "        # 由於貼圖與人臉同X軸計算IOU會非零，故貼圖平移右一像素\n",
    "        img_top_left = (int(bottom_right[0]),int(bottom_right[1]-img_wh))\n",
    "        img_bottom_right = (int(bottom_right[0]+img_wh),int(bottom_right[1]))\n",
    "        img_loc.append((img_top_left,img_bottom_right))\n",
    "        IoU_bottom_right.append(bb_intersection_over_union([img_top_left[0]+1,img_top_left[1],img_bottom_right[0]+1,img_bottom_right[1]],[x, y, x+w, y+h]))\n",
    "        \n",
    "        # 人臉左下半邊\n",
    "        # 由於貼圖與人臉同Y軸計算IOU會非零，故貼圖平移下一像素\n",
    "        img_top_left = (int(bottom_left[0]),int(bottom_left[1]))\n",
    "        img_bottom_right = (int(bottom_left[0]+img_wh),int(bottom_left[1]+img_wh))\n",
    "        img_loc.append((img_top_left,img_bottom_right))\n",
    "        IoU_bottom_left.append(bb_intersection_over_union([img_top_left[0],img_top_left[1]+1,img_bottom_right[0],img_bottom_right[1]+1],[x, y, x+w, y+h]))\n",
    "        \n",
    "        # 人臉右上半邊\n",
    "        # 由於貼圖與人臉同Y軸計算IOU會非零，故貼圖平移上一像素\n",
    "        img_top_left = (int(top_right[0]-img_wh),int(top_right[1]-img_wh))\n",
    "        img_bottom_right = (int(top_right[0]),int(top_right[1]))\n",
    "        img_loc.append((img_top_left,img_bottom_right))\n",
    "        IoU_top_right.append(bb_intersection_over_union([img_top_left[0],img_top_left[1]-1,img_bottom_right[0],img_bottom_right[1]-1],[x, y, x+w, y+h]))\n",
    "        \n",
    "        # 將左上與右下變數改為零，之後在IOU皆為零時會用到\n",
    "        img_top_left = 0\n",
    "        img_bottom_right = 0\n",
    "        \n",
    "    # 判斷貼圖與其他人臉的IOU是否為零，並針對四個角落，以及貼圖是否超過邊界之判斷\n",
    "    Iou_total = [IoU_top_left, IoU_bottom_right, IoU_bottom_left, IoU_top_right]\n",
    "    for i in range(len(Iou_total)):\n",
    "        if np.all(np.array(Iou_total[i]) == 0):\n",
    "            if img_loc[i][0][0]>0 and img_loc[i][0][1]>0 and img_loc[i][1][0]<frame.shape[1] and img_loc[i][1][1]<frame.shape[0]:\n",
    "                img_top_left, img_bottom_right = img_loc[i]\n",
    "\n",
    "    # 將左上與右下變數為非零時才貼圖，即上面非四個條件式都為Flase時才貼圖\n",
    "    if img_top_left != 0 and img_bottom_right != 0:\n",
    "        \n",
    "        # 轉為灰階\n",
    "        img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # 二值化\n",
    "        _, mask = cv2.threshold(img_gray, 25, 255, cv2.THRESH_BINARY_INV)\n",
    "    \n",
    "        area = frame[img_top_left[1]: img_top_left[1]+img_wh, img_top_left[0]: img_top_left[0]+img_wh]\n",
    "        area_no = cv2.bitwise_and(area,area,mask=mask)\n",
    "        final = cv2.add(area_no, img)\n",
    "        frame[img_top_left[1]: img_top_left[1]+img_wh, img_top_left[0]: img_top_left[0]+img_wh] = final\n",
    "\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = cv2.imread(\"Image_test/Face_test6.jpg\")\n",
    "img = cv2.resize(img, None, fx=1.5, fy=1.5)\n",
    "data, frame = face_check(img, model)\n",
    "\n",
    "cv2.imwrite(\"Face_test_fer.jpg\",frame)\n",
    "\n",
    "frame = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "plt.figure(figsize=(25,20))\n",
    "plt.imshow(frame)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "VIDEO_IN = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    hasFrame, img = VIDEO_IN.read()\n",
    "    img = cv2.resize(img, None, fx=0.5, fy=0.5)\n",
    "    data, img = face_check(img, model)\n",
    "    cv2.imshow(\"Frame\", img)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "        \n",
    "VIDEO_IN.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
